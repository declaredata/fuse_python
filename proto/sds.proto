syntax = "proto3";

package sds;

service sds {
    ////////////////////////////////////////
    // session/dataframe initialization methods
    ////////////////////////////////////////

    // execute SQL against a session and return a new DataFrame representing
    // the result
    rpc ExecuteSql (ExecuteSqlRequest) returns (DataFrameUID);
    // create a new session with no DataFrames therein, then return its UID
    rpc CreateSession(Empty) returns (SessionUID);
    // Load a CSV into a DataFrame, then return its UID
    rpc LoadCSV(LoadFileRequest) returns (DataFrameUID);
    // Load a Parquet file into a DataFrame, then return its UID
    rpc LoadParquet(LoadFileRequest) returns (DataFrameUID);
    // Load a JSON file into a DataFrame, then return its UID
    rpc LoadJSON(LoadFileRequest) returns (DataFrameUID);

    ////////////////////////////////////////
    // session destruction methods
    ////////////////////////////////////////

    // Close a session and free all associated dataframes.
    // 
    // This is a highly destructive method, because all dataframes
    // created directly or indirectly as part of this session
    // will be instantly deleted.
    rpc CloseSession (SessionUID) returns (Empty);
    
    ////////////////////////////////////////
    // dataframe instance methods
    ////////////////////////////////////////

    // save a dataframe as a table, so that you can execute SQL queries 
    // against it
    rpc SaveDataFrameAsTable(SaveDataFrameAsTableRequest) returns (Empty);
    // pretty-print a given dataframe.
    //
    // TODO: throw an error if the dataframe is too big to pretty-print
    rpc PrettyPrintDataframe(DataFrameUID) returns (PrettyPrintDataframeResponse);
    // filter an existing DataFrame, and return a new DataFrame
    rpc LimitDataFrame(LimitDataFrameRequest) returns (DataFrameUID);
    // sort a dataframe by 1 or more column(s)
    rpc SortDataFrame(SortDataFrameRequest) returns (DataFrameUID);
    // filter a dataframe according to 1 or more filter conditions
    rpc FilterDataFrame(FilterDataFrameRequest) returns (DataFrameUID);
    // group by, then aggregate a dataframe's data, the return a new dataframe
    rpc Aggregate(AggregateRequest) returns (DataFrameUID);
    // add a new column -- optionally by doing some calculation -- to a 
    // given dataframe
    rpc WithColumn(WithColumnRequest) returns (DataFrameUID);
    // project a DataFrame onto a new one, optionally by calculating new
    // values
    rpc Select(SelectRequest) returns (DataFrameUID);
    // eagerly evaluate the dataframe, then return its contents
    rpc Collect(DataFrameUID) returns (DataFrameContents);
    // Join 2 dataframes together into one
    rpc Join(JoinRequest) returns (DataFrameUID);
    // Return a new DataFrame whose contents are the same as the given
    // DataFrame, except with duplicate rows removed
    rpc Distinct(DataFrameUID) returns (DataFrameUID);
    // Combine two DataFrames together to calculate the union of the two.
    // 
    // Both DataFrames must have the same schema. If they do not, return
    // an error. If they do, preserve duplicate rows in the final result.
    rpc Union(UnionRequest) returns (DataFrameUID);
    // return a new DataFrame with the given columns missing.
    // 
    // if you pass a column that does not exist, this entire operation
    // will be a no-op and you'll get the same UUID back
    rpc Drop(DropRequest) returns (DataFrameUID);
    // export a CSV file and return it in the response
    rpc ExportCSV(DataFrameUID) returns (CSVOutput);
}

message Empty {}

message ExecuteSqlRequest {
    string session_uid = 1;
    string query = 2;
}

message SessionUID {
    string session_uid = 1;
}

message DataFrameUID {
    string dataframe_uid = 1;
}

message SaveDataFrameAsTableRequest {
    string dataframe_uid = 1;
    string table_name = 2;
}

message LoadFileRequest {
    string session_id = 1;
    string source = 2;
}

message PrettyPrintDataframeResponse {
    string content = 1;
}

// limit a dataframe to fields in the range [start, end)
//
// (includes start but not end)
message LimitDataFrameRequest {
    string dataframe_uid = 1;
    uint64 start = 2;
    uint64 end = 3;

}

message CSVOutput {
    string content = 1;
}

message SortDataFrameRequest {
    string dataframe_uid = 1;
    repeated SortColumn columns = 2;
}

message FilterCondition {
    string left = 1;
    string operator = 2;
    string right = 3;
}

message FilterDataFrameRequest {
    string dataframe_uid = 1;
    repeated FilterCondition conditions = 2;
}

message AggregateRequest {
    string dataframe_uid = 1;
    repeated string group_by = 2;
    repeated Agg aggs = 3;
}

enum SortDirection {
    ASC = 0;
    DESC = 1;
}
message SortColumn {
    string col_name = 1;
    SortDirection direction = 2;
}

enum AggOperation {
    SUM = 0;
    COUNT = 1;
    MIN = 2;
    MAX = 3;
    FIRST = 4;
    LAST = 5;
}

message Agg {
    string col_name = 1;
    AggOperation op = 2;
    optional string alias = 3;
    optional WindowSpec window = 4;
}

message WithColumnRequest {
    // the DataFrame from which to compute the new column
    string dataframe_uid = 1;
    // the name of the new column. the new column will be available
    // in a _new_ dataframe. the existing one will not be modified
    string new_col_name = 2;
    // the aggregation to be applied, to create the new column
    Agg aggregation = 3;
}

message WindowSpec {
    string partition_by = 1;
    string order_by = 2;
    uint64 left_boundary = 3;
    uint64 right_boundary = 4;
}

// the data in a single DataFrame row, including the column names.
// 
// we purposely do not deduplicate column names in case a set of rows
// have heterogenous data
message Row {
    map<string, Value> data = 1;
}

// used to represent a null value in a row
enum NullValue {
    NULL = 0;
}

message Value {
    oneof value {
        string string_value = 1;
        int64 int64_value = 2;
        int32 int32_value = 3;
        bytes bytes_value = 4;
        NullValue null_value = 5;
    }
}

message DataFrameContents {
    repeated Row rows = 2;
}

message SelectRequest {
    string df_uid = 1;
    repeated Column columns = 2;
}

// The definition of a column in Fuse.
// 
// This is either a reference to an existing column or a specification
// for how to compute a new column, possibly from an existing column.
message Column {
    oneof col_spec {
        string col_name = 1;
        NamedDerivedColumn col_derived = 2;
    }
}

// A new column that is derived by performing a binary operation 
// on an existing column with a constant. for example:
// 
//  existing_col + 2
// 
// The following expression would _not_ be supported by 
// ConstBinaryOpDerivedColumn
// 
//  existing_col + other_existing_col
// 
// because this is not an expression representing an existing column with a 
// binary operation applied to a constant (it's applied to a 2nd existing
// column)
message NamedDerivedColumn {
    string src_col = 1;
    string new_col = 2;
    string operator = 3;
    oneof constant {
        string str_val = 4;
        int32 i32_val = 5;
        int64 i64_val = 6;
    };
}

message DropRequest {
    string df_uid = 1;
    repeated string col_names = 2;
}

enum JoinType {
    INNER = 0;
    LEFT = 1;
    RIGHT = 2;
    FULL = 3;
}

message JoinRequest {
    string df_uid_1 = 1;
    string df_uid_2 = 2;
    JoinType join_type = 3;
    repeated string left_cols = 4;
    repeated string right_cols = 5;
}

message UnionRequest {
    string df_uid_1 = 1;
    string df_uid_2 = 2;
}
